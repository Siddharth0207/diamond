from langchain_core.prompts import PromptTemplate
from langchain_nvidia_ai_endpoints import ChatNVIDIA
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import TextLoader
#from langchain.vectorstores import Chroma
from langchain_community.document_loaders import YoutubeLoader

from dotenv import load_dotenv
import os 

load_dotenv()

def load_model():
    """
    Initializes the LLM with the desired configurations.
    
    Returns:
        ChatNVIDIA: An instance of the ChatNVIDIA model configured for use.
    """
    llm = ChatNVIDIA(
        model="meta/llama-3.3-70b-instruct",
        task='chat',
        temperature=0.6,
        top_p=0.7,
        max_tokens=4096,
    )
    return llm

def load_text_document():
    pass

def llm_text_response(transcription_result: str):
    """
    Generates a response from the LLM based on the transcription result.
    
    Args:
        transcription_result (str): The transcription result from the audio file.
        
    Returns:
        str: The response generated by the LLM.
    """
    llm = load_model()
    prompt = PromptTemplate(
        template="You are a very helpful assistant and You will Explain the given {text} more elaborately",
        input_variables=["text"]
    )

    parser = StrOutputParser()
    llm_chain = prompt | llm | parser
    response = llm_chain.ainvoke({'text': transcription_result})
    return response



loader = YoutubeLoader.from_youtube_url(
    "https://www.youtube.com/watch?v=MwXk5rcnUy0", add_video_info=False
)
print(loader.load())